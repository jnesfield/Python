{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# hypothesis testing\r\n",
        "\r\n",
        "a nice set of working things"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "#chi squared\r\n",
        "from scipy.stats import chi2_contingency, chi2\r\n",
        "\r\n",
        "def chi_test(arr):\r\n",
        "\r\n",
        "  \"\"\"\r\n",
        "  chi_test function takes a pandas df and breaks it into a numpy array for testing of independence\r\n",
        "  can also do fisher exact if testing on small counts...\r\n",
        "  \r\n",
        "  input:\r\n",
        "  arr - numpy array of count data\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  alpha = 0.05\r\n",
        "\r\n",
        "  #array is struct of (pna, non-pna)\r\n",
        "  stat, p, dof, expected = chi2_contingency(arr, correction = False)\r\n",
        "\r\n",
        "  prob = 1 - alpha\r\n",
        "\r\n",
        "  # interpet test statistic\r\n",
        "  critical = chi2.ppf(prob, dof)\r\n",
        "  print(\"probability ={}, critical ={}, stat={}, p value = {}\".format(prob, critical, stat, p))\r\n",
        "\r\n",
        "  if abs(stat) >= critical:\r\n",
        "    print('accept alternative hypothesis; counts are dependent on categories')\r\n",
        "  else:\r\n",
        "    print('maintain null hypothesis; counts are not dependent on categories')\r\n",
        "\r\n",
        "  print('contingency table:\\n', arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from statsmodels.stats.proportion import proportions_ztest\r\n",
        "\r\n",
        "def z_test(yes_count, yes_target, yes_label, no_count, no_target, no_label, alpha = 0.05):\r\n",
        "  \r\n",
        "  \"\"\"\r\n",
        "  z test function runs a z test to see if one proportion is higher with any significance\r\n",
        "  yes proportion must be smaller than no, other wise the alternative in the stats models function needs to be altered\r\n",
        "  also gives effect sizes\r\n",
        "  \r\n",
        "  inputs:\r\n",
        "  yes_count = sum count of observations for one class\r\n",
        "  yes_target = sum count of successful observations for one class\r\n",
        "  no_count = sum count of observations for one class\r\n",
        "  no_target = sum count of successful observations for one class\r\n",
        "  \r\n",
        "  \"\"\"\r\n",
        "  \r\n",
        "  if yes_target/yes_count > no_target/no_count:\r\n",
        "    print('proportions are not aligned properly')\r\n",
        "    return None\r\n",
        "\r\n",
        "  nobs = np.array([yes_count, no_count])\r\n",
        "  count = np.array([yes_target, no_target])\r\n",
        "  print(\"observations\" , nobs)\r\n",
        "  print(\"counts\", count)\r\n",
        "  \r\n",
        "  print(\"proportion \", yes_label, \": \", round(yes_target/yes_count,2))\r\n",
        "  print(\"proportion \", no_label, \": \", round(no_target/no_count,2))\r\n",
        "\r\n",
        "  stat, pval = proportions_ztest(count, nobs, alternative = 'smaller')\r\n",
        "  #smaller is when elements 0 have smaller proportion than elements 1\r\n",
        "\r\n",
        "  print('{0:0.3f}'.format(pval))\r\n",
        "\r\n",
        "  print(pval)  \r\n",
        "\r\n",
        "  if pval <= alpha:\r\n",
        "    print(\"accept alternative hypothesis that \", no_label, \" patients have a higher pick up rate\")\r\n",
        "  else:\r\n",
        "    print(\"maintain null hypothesis that there is no statistical significance that \", no_label, \" patients have a higher pick up rate\")\r\n",
        "    \r\n",
        "  #put smaller proportion thru last to get a positive effect size\r\n",
        "  effect = proportion_effectsize(no_target/no_count, yes_target/yes_count)\r\n",
        "  print(\"proportion effect size: \", effect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "\r\n",
        "#shapiro-wilks normality test\r\n",
        "from scipy.stats import shapiro\r\n",
        "\r\n",
        "def normality_test(data, alpha = 0.05):\r\n",
        "  stat, p = shapiro(data)\r\n",
        "  print('Statistics=%.3f, p=%.3f' % (stat, p))\r\n",
        "  \r\n",
        "  response = 1 #0 = normal\r\n",
        "  \r\n",
        "  if p >= alpha:\r\n",
        "    print(\"data is normally distributed\")\r\n",
        "  else:\r\n",
        "    print(\"data is not normally distributed\")\r\n",
        "    response = 0\r\n",
        "  \r\n",
        "  return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "import numpy as np\r\n",
        "from scipy.stats import mannwhitneyu\r\n",
        "from scipy.stats import tiecorrect, rankdata, norm\r\n",
        "\r\n",
        "def mann_whitney(data1, data2, alpha = .05): \r\n",
        "  #calculates significance of diff in means and effect\r\n",
        "  #this is a base two sided test\r\n",
        "  #data 1 must be less than data 2\r\n",
        "  #otherwise tweak alternative\r\n",
        "\r\n",
        "  # compare samples\r\n",
        "  stat, p = mannwhitneyu(data1, data2, alternative=\"less\")\r\n",
        "  print('Statistics=%.3f, p=%.3f' % (stat, p))\r\n",
        "  # interpret\r\n",
        "  #alpha = 0.05\r\n",
        "  if p > alpha:\r\n",
        "    print('Same distribution (fail to reject H0)', '\\nIn terms of this analysis this means that the difference in means is NOT due to the different categories!')\r\n",
        "  else:\r\n",
        "    print('Different distribution (reject H0)', '\\nIn terms of this analysis this means that the difference in means is due to the different categories!')\r\n",
        "\r\n",
        "  #calculate effect size:\r\n",
        "  #borroewd from https://github.com/Hatchin/Mann-Whitney-U-Test/blob/master/mannwhitney.py\r\n",
        "  n1 = len(data1)\r\n",
        "  n2 = len(data2)\r\n",
        "  ranked = rankdata(np.concatenate((data1, data2)))\r\n",
        "  rankx = ranked[0:n1]  # get the x-ranks\r\n",
        "  u1 = n1*n2 + (n1*(n1+1))/2.0 - np.sum(rankx, axis=0)  # calc U for x\r\n",
        "  u2 = n1*n2 - u1  # remainder is U for y\r\n",
        "\r\n",
        "  # use the min(u1, u2) as u-stat\r\n",
        "  if u1 <= u2:\r\n",
        "      stat_a, larger = u1, 1\r\n",
        "  else:\r\n",
        "      stat_a, larger = u2, 2\r\n",
        "\r\n",
        "  # compute the effect size    \r\n",
        "  effect = 1 - (2*stat_a)/(n1*n2) \r\n",
        "  \r\n",
        "  if effect < .3:\r\n",
        "    print('This has a small effect; the effect size for this test is : %.3f' % effect)\r\n",
        "  elif effect > .5:\r\n",
        "    print('This has a large effect; the effect size for this test is : %.3f' % effect)\r\n",
        "  else:\r\n",
        "    print('This has a medium effect; the effect size for this test is : %.3f' % effect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from scipy.stats import ttest_ind\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "def t_test(data1, data2, alpha = 0.05):\r\n",
        "  \"\"\"\r\n",
        "  t test function to measure if mean of data1 is less than mean of data2\r\n",
        "  \"\"\"\r\n",
        "  d1_var = np.var(data1)\r\n",
        "  d2_var = np.var(data2)\r\n",
        "  \r\n",
        "  equal_var = False\r\n",
        "  \r\n",
        "  if round(d1_var,4) == round(d2_var,4):\r\n",
        "    equal_var = True\r\n",
        "  \r\n",
        "  stat, p = ttest_ind(data1, data2, axis = 0, equal_var = equal_var, alternative = 'less')\r\n",
        "  \r\n",
        "  print('Statistics=%.3f, p=%.3f' % (stat, p))\r\n",
        "  \r\n",
        "  if p > alpha:\r\n",
        "    print(\"maintain null hypothesis that means are not significantly different\")\r\n",
        "  else:\r\n",
        "    print(\"accept alternative hypothesis that means are significantly different\")\r\n",
        "    \r\n",
        "  #effect size (cohen's d calc)\r\n",
        "  #machine learning mastery formula\r\n",
        "  n1, n2 = len(data1), len(data2)\r\n",
        "  \r\n",
        "  u1, u2 = np.mean(data1), np.mean(data2)\r\n",
        "  \r\n",
        "  #pooled standard deviation\r\n",
        "  s = sqrt((((n1 -1) * d1_var) + ((n2 - 1) * d2_var))/(n1 + n2 -2))\r\n",
        "  \r\n",
        "  #flipped u so as to show a positive effect measure\r\n",
        "  d = (u2 - u1)/s\r\n",
        "           \r\n",
        "  if d < .2: \r\n",
        "    print('Cohens d shows a small effect (if your data is nor normal/gaussian this is junk!): %.3f' % d)\r\n",
        "  elif d > .8:\r\n",
        "    print('Cohens d shows a large effect (if your data is nor normal/gaussian this is junk!): %.3f' % d)\r\n",
        "  else:\r\n",
        "    print('Cohens d shows a medium effect (if your data is nor normal/gaussian this is junk!): %.3f' % d)"
      ]
    }
  ]
}