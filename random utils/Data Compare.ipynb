{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Compare\n",
    "\n",
    "Compare data to derive insights.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chi squared\n",
    "from scipy.stats import chi2_contingency, chi2\n",
    "\n",
    "def chi_test(arr):\n",
    "\n",
    "    \"\"\"\n",
    "    chi_test function takes a pandas df and breaks it into a numpy array for testing of independence\n",
    "\n",
    "    input:\n",
    "    arr - numpy array of count data\n",
    "    \"\"\"\n",
    "\n",
    "    alpha = 0.05\n",
    "\n",
    "    #array is struct of (pna, non-pna)\n",
    "    stat, p, dof, expected = chi2_contingency(arr, correction = False)\n",
    "\n",
    "    prob = 1 - alpha\n",
    "\n",
    "    # interpet test statistic\n",
    "    critical = chi2.ppf(prob, dof)\n",
    "    print(\"probability ={}, critical ={}, stat={}, p value = {}\".format(prob, critical, stat, p))\n",
    "\n",
    "    if abs(stat) >= critical:\n",
    "        print('accept alternative hypothesis; counts are dependent on categories')\n",
    "    else:\n",
    "        print('maintain null hypothesis; counts are not dependent on categories')\n",
    "\n",
    "        print('contingency table:\\n', arr)\n",
    "\n",
    "#z test on proportions where yes proportion is smaller than no\n",
    "import numpy as np\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "from statsmodels.stats.proportion import proportion_effectsize\n",
    "\n",
    "def z_test(yes_count, yes_target, yes_label, no_count, no_target, no_label, alpha = 0.05):\n",
    "  \n",
    "    \"\"\"\n",
    "    z test function runs a z test to see if one proportion is higher with any significance\n",
    "    yes proportion must be smaller than no, other wise the alternative in the stats models function needs to be altered\n",
    "    also gives effect sizes\n",
    "\n",
    "    inputs:\n",
    "    yes_count = sum count of observations for one class\n",
    "    yes_target = sum count of successful observations for one class\n",
    "    no_count = sum count of observations for one class\n",
    "    no_target = sum count of successful observations for one class\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if yes_target/yes_count > no_target/no_count:\n",
    "    print('proportions are not aligned properly')\n",
    "    return None\n",
    "\n",
    "    nobs = np.array([yes_count, no_count])\n",
    "    count = np.array([yes_target, no_target])\n",
    "    print(\"observations\" , nobs)\n",
    "    print(\"counts\", count)\n",
    "\n",
    "    print(\"proportion \", yes_label, \": \", round(yes_target/yes_count,2))\n",
    "    print(\"proportion \", no_label, \": \", round(no_target/no_count,2))\n",
    "\n",
    "    stat, pval = proportions_ztest(count, nobs, alternative = 'smaller')\n",
    "    #smaller is when elements 0 have smaller proportion than elements 1\n",
    "\n",
    "    print('{0:0.3f}'.format(pval))\n",
    "\n",
    "    print(pval)  \n",
    "\n",
    "    if pval <= alpha:\n",
    "        print(\"accept alternative hypothesis that \", no_label, \"  have a higher proportion\")\n",
    "    else:\n",
    "        print(\"maintain null hypothesis there is no significance that \", no_label, \" have a higher proportion\")\n",
    "\n",
    "    #put smaller proportion thru last to get a positive effect size\n",
    "    effect = proportion_effectsize(no_target/no_count, yes_target/yes_count)\n",
    "        print(\"proportion effect size: \", effect)\n",
    "\n",
    "\n",
    "#shapiro-wilks normality test\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "def normality_test(data, alpha = 0.05):\n",
    "    stat, p = shapiro(data)\n",
    "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "    response = 1 #0 = normal\n",
    "\n",
    "    if p >= alpha:\n",
    "        print(\"data is normally distributed\")\n",
    "    else:\n",
    "        print(\"data is not normally distributed\")\n",
    "    response = 0\n",
    "\n",
    "    return response\n",
    "\n",
    "#mann whitney u test for non-normal data\n",
    "import numpy as np\n",
    "from scipy.stats import mannwhitneyu, tiecorrect, rankdata, norm\n",
    "\n",
    "def mann_whitney(data1, data2, alpha = .05): \n",
    "    #calculates significance of diff in means and effect\n",
    "    #this is a base two sided test\n",
    "\n",
    "    # compare samples\n",
    "    stat, p = mannwhitneyu(data1, data2, alternative=\"less\")\n",
    "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    # interpret\n",
    "    #alpha = 0.05\n",
    "    if p > alpha:\n",
    "        print('Same distribution (fail to reject H0)')\n",
    "        print('In terms of this analysis this means that the difference in means is NOT due to the different categories!')\n",
    "    else:\n",
    "        print('Different distribution (reject H0)')\n",
    "        print('In terms of this analysis this means that the difference in means is due to the different categories!')\n",
    "\n",
    "    #calculate effect size:\n",
    "    #borroewd from https://github.com/Hatchin/Mann-Whitney-U-Test/blob/master/mannwhitney.py\n",
    "    n1 = len(data1)\n",
    "    n2 = len(data2)\n",
    "    ranked = rankdata(np.concatenate((data1, data2)))\n",
    "    rankx = ranked[0:n1]  # get the x-ranks\n",
    "    u1 = n1*n2 + (n1*(n1+1))/2.0 - np.sum(rankx, axis=0)  # calc U for x\n",
    "    u2 = n1*n2 - u1  # remainder is U for y\n",
    "\n",
    "    # use the min(u1, u2) as u-stat\n",
    "    if u1 <= u2:\n",
    "        stat_a, larger = u1, 1\n",
    "    else:\n",
    "        stat_a, larger = u2, 2\n",
    "\n",
    "    # compute the effect size    \n",
    "    effect = 1 - (2*stat_a)/(n1*n2) \n",
    "\n",
    "    if effect < .3:\n",
    "        print('This has a small effect; the effect size for this test is : %.3f' % effect)\n",
    "    elif effect > .5:\n",
    "        print('This has a large effect; the effect size for this test is : %.3f' % effect)\n",
    "    else:\n",
    "        print('This has a medium effect; the effect size for this test is : %.3f' % effect)\n",
    "    \n",
    "#t-test for normal data\n",
    "from scipy.stats import ttest_ind\n",
    "from numpy import mean, var, sqrt\n",
    "\n",
    "def t_test(data1, data2, alpha = 0.05):\n",
    "    \"\"\"\n",
    "    t test function to measure if mean of data1 is less than mean of data2\n",
    "    \"\"\"\n",
    "    d1_var = var(data1)\n",
    "    d2_var = var(data2)\n",
    "\n",
    "    equal_var = False\n",
    "\n",
    "    if round(d1_var,4) == round(d2_var,4):\n",
    "        equal_var = True\n",
    "        \n",
    "    print(\"Are variances equal?: \", equal_var)\n",
    "\n",
    "    stat, p = ttest_ind(data1, data2, axis = 0, equal_var = equal_var, alternative = 'less')\n",
    "\n",
    "    print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "    if p > alpha:\n",
    "        print(\"maintain null hypothesis that means are not significantly different\")\n",
    "    else:\n",
    "        print(\"accept alternative hypothesis that means are significantly different\")\n",
    "\n",
    "    #effect size (cohen's d calc)\n",
    "    #machine learning mastery formula\n",
    "    n1, n2 = len(data1), len(data2)\n",
    "\n",
    "    u1, u2 = mean(data1), mean(data2)\n",
    "\n",
    "    #pooled standard deviation\n",
    "    s = sqrt((((n1 -1) * d1_var) + ((n2 - 1) * d2_var))/(n1 + n2 -2))\n",
    "\n",
    "    #flipped u so as to show a positive effect measure\n",
    "    d = (u2 - u1)/s\n",
    "\n",
    "    if d < .2: \n",
    "        print('Cohens d shows a small effect (if your data is nor normal/gaussian this is junk!): %.3f' % d)\n",
    "    elif d > .8:\n",
    "        print('Cohens d shows a large effect (if your data is nor normal/gaussian this is junk!): %.3f' % d)\n",
    "    else:\n",
    "        print('Cohens d shows a medium effect (if your data is nor normal/gaussian this is junk!): %.3f' % d)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Less Basic\n",
    "\n",
    "feature correlation to output; run binary output against features to get general correlation direction\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pointbiserialr.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pointbiserialr, ks_2samp\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def feature_correlation(df, feat_list, target):\n",
    "    \n",
    "    sorted_feat_col_name = []\n",
    "    sorted_correlation = []\n",
    "    correlation_color = []\n",
    "\n",
    "    for feat in feat_list:\n",
    "        sorted_feat_col_name.append(feat)\n",
    "\n",
    "        correlation = pointbiserialr(df[feat].fillna(0), df[target])[0]\n",
    "        print(correlation)\n",
    "        sorted_correlation.append(correlation)\n",
    "\n",
    "        if correlation == 0:\n",
    "            color = 'b'\n",
    "        elif correlation > 0:\n",
    "            color = 'g'\n",
    "        else:\n",
    "            color = 'r'\n",
    "\n",
    "        correlation_color.append(color)\n",
    "        \n",
    "    #plt.title('Feature Importances')\n",
    "    plt.rcParams.update({'figure.figsize':[7,5]}) #(w,h)\n",
    "    plt.barh(range(len(sorted_importance)), sorted_importance, color=correlation_color, align='center')\n",
    "    plt.yticks(range(len(actual_names)), actual_names)\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.show()      \n",
    "\n",
    "def js_divergence(p, q, base=None):\n",
    "    \"\"\"\n",
    "    test function for jensen-shannon distance\n",
    "    references:\n",
    "    https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence\n",
    "    https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.jensenshannon.html\n",
    "    \n",
    "    there is not really a great way to interpet this atm, I have been searching for a hypothesis test version of this!\n",
    "\n",
    "    input:\n",
    "    p: distrib to test\n",
    "    q: base distribution (validation data)\n",
    "    base: base of the logarithm used ot compute the distance\n",
    "    \"\"\"\n",
    "\n",
    "    distance =  jensenshannon(p, q, base=base)\n",
    "    return distance      \n",
    "\n",
    "def ks_testing(p, q, ks_alternative=\"two-sided\", mode=\"asymp\")\n",
    "    \"\"\"\n",
    "    test function for two sample ks testing\n",
    "    references:\n",
    "    https://www.sciencedirect.com/topics/earth-and-planetary-sciences/kolmogorov-smirnov-test\n",
    "    The null hypothesis (Ho) is that the two dataset values are from the same continuous distribution. \n",
    "    The alternative hypothesis (Ha) is that these two datasets are from different continuous distributions. \n",
    "    \n",
    "    https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks_2samp.html\n",
    "\n",
    "    input:\n",
    "    p: distrib to test\n",
    "    q: base distribution (validation data)\n",
    "    ks_alternative{‘two-sided’, ‘less’, ‘greater’}, optional\n",
    "        we use two sided where the null hyp is the distribs are the same.\n",
    "    \"\"\"\n",
    "\n",
    "    ks_stat, ks_pval = ks_2samp(p, q alternative=ks_alternative, mode=\"asymp\", alpha = 0.05)\n",
    "    \n",
    "    print('Statistics=%.3f, p=%.3f' % (ks_stat, ks_pval))\n",
    "\n",
    "    if p > alpha:\n",
    "        print(\"maintain null hypothesis that distribs are not significantly different\")\n",
    "    else:\n",
    "        print(\"accept alternative hypothesis that distribs are significantly different\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
